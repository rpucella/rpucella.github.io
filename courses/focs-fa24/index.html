<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
    <title>Foundations of Computer Science (Fall 2024)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="/static/main.css" type="text/css">
    <link rel="stylesheet" href="/courses/course.css" type="text/css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">

    <script src="/static/smooth-scroll.js"></script>

    <style>
      body {
          font-size: 120%;
      }

      section {
          border-top: 1px solid rgb(90, 0, 0);
      }
    </style>

  </head>

  <body>

    <nav>

      <div class="home">
	<a href="/"><img src="/home.png" style="height: 1.6em;"></a>
      </div>

      <ul>
	<li><a class="smooth-scroll" href="#main"><b>Foundations of Computer Science FA24</b></a></li>
	<li><a class="smooth-scroll" href="#info">Course Info</a></li>
	<li><a class="smooth-scroll" href="#lectures">Lectures</a></li>
	<li><a class="smooth-scroll" href="#homeworks">Homeworks</a></li>
      </ul>
    </nav>


    
<main id="main">
  
      <h1>Foundations of Computer Science (Fall 2024)</h1>
    
      <p>This course explores the notion of computation. We're going to
        develop formal tools for defining what we mean by computation
        through various models, including automata and the lambda
        calculus. We will examine how some of these alternative models
        of computations correspond to different programming paradigms.
      </p>
      
      <section id="info">
        <h2>Course Information</h2>

        <ul class="plain">
          <li><b>Course number:</b> ENGR 3520</li>

          <li><b>Prerequisites:</b> Prior experience programming is required (Software Design or something equivalent) since I will not teach programming. Discrete Mathematics is no longer a formal prerequisite for FoCS, but it may make your life easier.</li>

          <li><b>Location and Time:</b>
            MAC 328 / Mon 6-8:40pm
          </li>

          <li><b>Instructor:</b> <a href="https://www.rpucella.net">Riccardo Pucella</a> (&#x72;&#x69;&#x63;&#x63;&#x61;&#x72;&#x64;&#x6F;&#x2E;&#x70;&#x75;&#x63;&#x65;&#x6C;&#x6C;&#x61;&#x40;&#x6F;&#x6C;&#x69;&#x6E;&#x2E;&#x65;&#x64;&#x75;)</li>

          <li><b>Office hours:</b> MH 353 / Mon 4-5pm (before class) / I'm available at other times over Zoom by request
          </li>

          <li><b>Textbook:</b> There is no required textbook for the course. We will be working off
            notes and online references.
          </li>

          <li><b>Recommended Books:</b> There are several excellent books covering the first part of
            the course (aka, theory of computation), but they are a bit expensive considering that
            we will be covering only a small part of their content. If you need extra assistance,
            though, any of these books would be useful, and they are on reserve in the Olin library:
            
            <ul>
              <li>Chen, <i><a href="https://www.amazon.com/Computability-Complexity-Hubie-Chen/dp/0262048620">Computability and Complexity</a></i></li>
              <li>Sipser, <i><a href="https://www.amazon.com/Introduction-Theory-Computation-Michael-Sipser/dp/1133187811">Introduction to the Theory of Computation</a></i></li>
	      <li>Hopcroft, Motwani, Ullman, <i><a href="https://www.amazon.com/Introduction-Automata-Theory-Languages-Computation/dp/0321455363">Automata Theory, Languages, and Computation</a></i></li>
            </ul>
            
            An inexpensive and reasonable book is the following, although it uses Ruby instead of Python:
            <ul>
	      <li>Stuart, <i><a href="http://computationbook.com">Understanding Computation</a></i></li>
            </ul>
            It very much follows the spirit of this iteration of FoCS. Again, not required. But if you enjoy the course, you may enjoy the book.
            
          </li>

          
          <li><p><b>Programming:</b> All programming in the course
            will be done in <a
            href="https://www.python.org/downloads/">Python 3</a>. I
            will assume working knowledge of the language. We will
            largely follow the <a
            href="http://legacy.python.org/dev/peps/pep-0008/">PEP8
            style guide</a>, and you may also want to read through <a
            href="https://www.memonic.com/user/pneff/folder/python/id/1bufp">this</a>
            as well.</li>
          
          <li><b>Grading:</b> The final grade is based on weekly homework (30%), in-class quizzes
            (30%), and a team final project (40%). Homeworks and quizzes will be done
            individually. Late homeworks will be penalized (5% per 24 hours) and no homework will be
            accepted after its solution has been discussed in class.  </li>

          <li><b>Course Assistant:</b> Ben Kim (details to follow)
          </li>

          <li>Discussions for this course and homework submissions will take place over on <a href="https://canvas.olin.edu/courses/820">Canvas</a>.</li>

          <li>I expect all of us to follow the <b><a href="http://www.olin.edu/academic-life/student-affairs-resources/student-life/honor-code/">Olin Honor Code</a></b>.</li>


  </section>

  <section id="lectures">

    <h2>
      Lectures and Readings
    </h2>

    <p>Subject to changes.</p>

    <ul class="lectures">

      <li><p><span class="hdr">Sep 9: </span><b>Introduction</b></p>
        <div class="lect">
	   <p><a href="https://en.wikipedia.org/wiki/Hilbert's_problems">Hilbert's problems</a>, ten of
	     which were presented at the ICM in Paris in
	     1900. His <a href="https://en.wikipedia.org/wiki/Hilbert's_tenth_problem">tenth
	       problem</a>, on the solvability of Diphantine equations, spoke directly to the notion of
	     computation.</p>
           
           <p>The mathematical notions we'll be using are in Chen
           above, pages 8-10.  Here's <a href="languages.pdf">additional notes</a> on what I presented in class.
           
	   <p>When talking about set comprehension, I mentioned that there usually needs to be some
	     restrictions on the properties allowed in order to ensure that the sets can be constructed
	     by comprehension. <a href="https://plato.stanford.edu/entries/russell-paradox/">Russell's
	       Paradox</a> is why we need such restrictions.</p>
           
	   <p>You may have noticed that union, intersection, and complementation of sets were defined
	     using set comprehensions that uses conjunction, disjunction, and negation,
	     respectively. This close connection between set operations and logic is a reflection of the
	     fact that sets form a <a href="https://en.wikipedia.org/wiki/Boolean_algebra">Boolean
	       algebra</a>.</p>
           
        </div>

      <li><p><b>MACHINE MODELS</b></p></li>

      <li><p><span class="hdr">Sep 16: </span><b>Deterministic Finite Automata, Regular Languages</b></p>
        <div class="lect">
           <p>Reading: Chen, Sections 1.1 - 1.2.</p>
           
           <p>Some <a href="dfa.pdf">notes</a> on what I presented in class.</p>
           
        </div>
      </li>

      <li><p><span class="hdr">Sep 23: </span><b>Nondeterministic Finite Automata, Regular Expressions</b></p>
        <div class="lect">
           <p>Reading: Chen, Sections 1.3 - 1.5.</p>

           <p>Some <a href="nfa.pdf">notes</a> on what I presented in class. These do not cover
           &epsilon;-NFAs, for which I will point you to the Chen notes.</p>

           <p>One reason to study nondeterministic finite automata is that they can be easier to
           describe than deterministic finite automata. More specifically, there exists languages
           that can be accepted by nondeterministic finite automata with N states whose smallest
           deterministic finite automata that accept those same languages have at least
           2<sup>N</sup> states. One example is the language over {<tt>a</tt>,<tt>b</tt>} consisting
           of all strings whose Nth from last symbol is <tt>a</tt>. <a
           href="https://commons.wikimedia.org/wiki/File:NFA_with_exponential_blown-up_DFA.gif">Here
           is an illustration</a> of the subset construction for that language, over alphabet {0,1},
           and N=4.</p>

<p>The construction to go from regular expressions to finite automata (via &epsilon;-NFAs) is known as <a href="https://en.wikipedia.org/wiki/Thompson%27s_construction">Thompson's construction</a> after Ken Thompson, one of the creators of Unix.</p>

	   <p>Regular expressions are used to search for patterns in text. <a href="http://www.cs.columbia.edu/~tal/3261/fall07/handout/egrep_mini-tutorial.htm">Here is an example of how they are used in egrep</a>. Note that the equivalence between regular expressions and regular languages only holds for <i>pure</i> regular expressions. Most regular expression packages used in practice extend regular expressions in ways that let you express non-regular languages.</p>
           
           <p>An <a href="https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html">interesting article by Brian Kernighan</a> on elegant code for regular expression matching. Note that Kernighan's definition of regular expressions is more restricted than ours. (The point of the article is not regular expressions, but elegant code.)</p>
           
	    <p>If you define two regular expressions to be equal when they denote the same set of strings, then regular expressions obey the laws of <a href="https://en.wikipedia.org/wiki/Kleene_algebra">Kleene algebras</a>.</p>

        </div>
      </li>
      
      <li><p><span class="hdr">Sep 30: </span><b>Pushdown Automata</b></p>
      <div class="lect">
        <p>Lecture notes shared privately on <a href="https://canvas.olin.edu/courses/820">Canvas</a>. </p>
	<p>Examples of languages that were not regular include
	    {a<sup>n</sup>b<sup>n</sup> | n &ge; 0}, {a<sup>n</sup>b<sup>n</sup>c<sup>n</sup> | n &ge; 0}, {a<sup>m</sup>b<sup>n</sup> | m &ge; n &ge; 0}, {u | u = reverse(u)}. I gave a direct argument in class for the first of these.. I haven't shown you any general way of showing that a language is not regular. The most common tool used is the <i>pumping lemma (for regular languages)</i>. Here's a reasonable <a href="https://courses.cs.washington.edu/courses/cse322/08au/lec9.pdf">reference</a>.</p>

        <p>Wikipedia links for: <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">pushdown automata</a>, <a href="https://en.wikipedia.org/wiki/Deterministic_pushdown_automaton">deterministic pushdown automata</a>.</p>
        <p>Unlike finite automata, deterministic pushdown automata are NOT equivalent to nondetermninistic pushdown automata. Nondeterminism genuinely give you more. For example, there is a nondeterministic pushdown automaton to accept (even length) palindromes over a given alphabet, but there is no such deterministic pushdown automaton.</p>
	</div>
      </li>

      <li><p><span class="hdr">Oct 7: </span><b>Context-Free Grammars</b></p>
      <div class="lect">
            <p>Succinct <a href="./grammars.pdf">notes</a> from the lecture. It mentions non-context-free grammars as well, which is not currently our interest.</p>

	    <p>Grammars are used in linguistics (introduced
	        by <a href="https://en.wikipedia.org/wiki/Syntactic_Structures">Chomsky
	        to study the structure of natural languages</a>) and
	        in computer science to implement parsers, that is,
	        turning a string of symbols into a structured artifact
	        like an Abstract Syntax Tree to represent a program in
	        a form that it more amenable to execution and/or
	        compilation. <a href="http://homepages.cwi.nl/~storm/teaching/sc1112/intro-parsing.pdf">Here's
	        a reasonable high-level presentation</a> of the basics
	        of parsing, to give you a flavor.</p>

	    <p>A beautiful application of grammars
	      is <a href="https://en.wikipedia.org/wiki/L-system">L-systems</a>,
	      a class of grammars that model the growth processes of plant
	      development.</p>

	    <p>I posted some additional notes on converting context-free grammars to and from pushdown automata on our <a href="https://canvas.olin.edu/courses/820">Canvas</a> site.</p>

	  </div>
      </li>

      <li><p><span class="hdr">Oct 17 (Olin Monday): </span><b>Turing Machines</b></p>
         <div class="lect">
           <p>Reading: Chen, Section 2.1, 2.6, 2.7</p>
	   <p>Quiz: finite state machines</p>
           
          <p>A <a href="./tm-anbn.png">diagram</a> of the Turing machine I showed in class to accept the langage {<tt>a</tt><sup>n</sup><tt>b</tt><sup>n</sup> | n &ge; 0}. If you want to practice, you can try to modify the machine to accept the languages {<tt>a</tt><sup>m</sup><tt>b</tt><sup>n</sup> | n &ge; m &ge; 0} and {<tt>a</tt><sup>n</sup><tt>b</tt><sup>n</sup><tt>c</tt><sup>n</sup> | n &ge; 0}.</p>
            
	  <p><a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf"><i>On Computable
	        Numbers, with an Application to the Entscheidungsproblem</i></a>, the original paper by
	    Turing that describes his machines. (Though it's not the most accessible
	    description.)</p>
	 </div>
	  
      </li>

      <li><p><span class="hdr">Oct 21: </span><b>The Church-Turing Thesis</b></p>
        <div class="lect">
	   <p>The <a href="https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis">Church-Turing
	       thesis</a>.</p>
           
           <p>Pithy mathematical description of <a
             href="https://en.wikipedia.org/wiki/Multitape_Turing_machine">multi-tape
             Turing machines</a>. Some additional notes on multitape
             Turing machines are available on our <a
             href="https://canvas.olin.edu/courses/820">Canvas</a>
             site.</p>

</p>

	    <p>A quick introduction
	      to <a href="https://en.wikipedia.org/wiki/Universal_Turing_machine">Universal
		Turing machines</a> from Wikipedia. Moore gives a <a href="moore.pdf">multi-tape implementation of a Universal Turing
		machine in 15 states</a>. It is from 1952, and it is a delightful (if somewhat opaque) time capsule. </p>

	</div>
      </li>

      <li><p><span class="hdr">Oct 28: </span><b>Non-Computable Languages</b></p>
        <div class="lect">
          <p>Reading: Chen, Sections 2.2 &ndash; 2.4</p>

            <p>Wikipedia links: the <a href="https://en.wikipedia.org/wiki/Halting_problem">Halting Problem</a>; <a href="https://en.wikipedia.org/wiki/Reduction_(complexity)">Reducibility</a>; <a href="https://en.wikipedia.org/wiki/Rice%27s_theorem">Rice's Theorem</a>.</p>

            <p>I mentioned that the non-computability of the halting problem for Turing machines impacts any kind of reasoning that we wish to make about programs in modern programming languages. This is a simple application of the Church-Turing thesis. Matthew Might has an accessible account that <a href="https://matt.might.net/articles/intro-static-analysis/">describes how the non-computability of the halting problem impacts static analysis of programs</a>.

            <p>The <a href="https://en.wikipedia.org/wiki/Post_correspondence_problem">Post Correspondence Problem</a> is non-computable, doesn't talk about Turing machines or interpreters for programming languages, and shows that there are reasonable problems that are non-computable. I've posted a proof of the non-computability of PCP on our Canvas site.</p>
	</div>
      </li>

      <li><p><b>CHURCH-TURING THESIS</b></p></li>

      <li><p><span class="hdr">Nov 4: </span><b>The Abacus Model</b></p>
      <div class="lect">
        <p>Quiz: pushdown automata</p>
        <p>My description of the Abacus model is taken from Lambek's <i><a href="https://www.math.mcgill.ca/barr/papers/pga.pdf">Programs, Grammars, Arguments</a></i>, Chapter 1. The other chapters are well worth reading too, though beyond what we're covering in this course.
      </div>
      </li>

      <li><p><span class="hdr">Nov 18 - Dec 9: </span><b>Compiling to Register Machines</b></p>
      <div class="lect">
        <p>Quiz (Nov 18): context-free grammars</p>
         <p>Quiz (Dev 9): Turing machines</p>
	 <p>Some very rough notes on <a href="compiler.html">compiling a language of while loops</a>. A follow-up <a href="compiling-while-loops.pdf">slide deck</a> going into more details of the compiler that I demo-ed in class.<p>
	 <p>(I will post the compiler's code here once I receive the last few Homework 6s. Check back after Christmas.)</p>
	 <p>The parser for the language I presented in class is based on parser combinators, which is a technique for parsing context-free grammars using backtracking. If you're interested in some of the theory underlying parser combinators, a good starting point is Graham Hutton's <a href="http://www.cs.nott.ac.uk/~pszgmh/parsing.pdf"><i>Higher-Order Functions for Parsing</i></a> tutorial.</p>
       </div>
      </li>

    </ul>

  </section>


  <section id="homeworks">
    
    <h2>Homeworks</h2>

    <ul class="plain">
      <li><a href="./homeworks/1">Homework 1</a> &mdash; due Sunday Sep 29</li>
      <li><a href="./homeworks/2">Homework 2</a> &mdash; due Tuesday Oct 8</li>
      <li><a href="./homeworks/3">Homework 3</a> &mdash; due Sunday Oct 13</li>
      <li><a href="./homeworks/4">Homework 4</a> &mdash; due Tuesday Oct 29</li>
      <li><a href="./homeworks/5">Homework 5</a> &mdash; due Tuesday Nov 19</li>
      <li><a href="./homeworks/6">Homework 6</a> &mdash; due Thursday Dec 12</li>
      <li><a href="./project/">Final Project</a> &mdash; due Friday Dec 20</li>
      </ul>  
    
  </section>
  
</main>

    
  </body>
</html>
